{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a5af49-a7fa-4d59-b79e-35c64262ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_llm_embedder import MyLLMEmbedder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dded2948-fcf3-4132-b79e-6fc314ea3cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>categories</th>\n",
       "      <th>business_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mG1FavLfA5j2L83sCZ3rFg</td>\n",
       "      <td>BLu9dc1uj_MBgR-Ns9bwQg</td>\n",
       "      <td>drTZrkbpSoJgwKETlFbc3w</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I bought a Fender 1966 Telecaster that the sal...</td>\n",
       "      <td>2022-01-01 15:47:07</td>\n",
       "      <td>2022</td>\n",
       "      <td>Shopping, Musical Instrument Services, Musical...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WMpnr1XBJ5U38rfSdErhJQ</td>\n",
       "      <td>0w1Cpzqg0LV93LmrWbmZnA</td>\n",
       "      <td>jyxHti29yWdYR00Itt1A2w</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is our go to for take out when I visit my...</td>\n",
       "      <td>2022-01-02 03:49:01</td>\n",
       "      <td>2022</td>\n",
       "      <td>Restaurants, Mediterranean</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99EMi0lRhdmylbG0soaf9w</td>\n",
       "      <td>QcP1iT3zKu7NQmiIlOg6XA</td>\n",
       "      <td>Jo4ei-c-5H53IxZxAVf1jQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Danielle did a great job!  She listened and cu...</td>\n",
       "      <td>2022-01-03 03:17:03</td>\n",
       "      <td>2022</td>\n",
       "      <td>Hair Salons, Men's Hair Salons, Barbers, Beaut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qs4z8e7hCoU9EzRKD9rGPQ</td>\n",
       "      <td>zH1VutqglmJPSvShRl07vg</td>\n",
       "      <td>YT5CjacTllBtvMaMJS3IbA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We saw a lot of roaches in the bathroom when w...</td>\n",
       "      <td>2022-01-05 15:55:59</td>\n",
       "      <td>2022</td>\n",
       "      <td>Hotels &amp; Travel, Hotels, Venues &amp; Event Spaces...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SXZ2Nw9UGAgPlXJsju9fFA</td>\n",
       "      <td>bvbmmVvkoxzTFzPc89WQhA</td>\n",
       "      <td>9MHe5jAym2d8VhT_NbCRyw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We  Ordered pork fried rice and beef chow mei ...</td>\n",
       "      <td>2022-01-06 03:59:21</td>\n",
       "      <td>2022</td>\n",
       "      <td>Restaurants, Chinese, Thai</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  mG1FavLfA5j2L83sCZ3rFg  BLu9dc1uj_MBgR-Ns9bwQg  drTZrkbpSoJgwKETlFbc3w   \n",
       "1  WMpnr1XBJ5U38rfSdErhJQ  0w1Cpzqg0LV93LmrWbmZnA  jyxHti29yWdYR00Itt1A2w   \n",
       "2  99EMi0lRhdmylbG0soaf9w  QcP1iT3zKu7NQmiIlOg6XA  Jo4ei-c-5H53IxZxAVf1jQ   \n",
       "3  Qs4z8e7hCoU9EzRKD9rGPQ  zH1VutqglmJPSvShRl07vg  YT5CjacTllBtvMaMJS3IbA   \n",
       "4  SXZ2Nw9UGAgPlXJsju9fFA  bvbmmVvkoxzTFzPc89WQhA  9MHe5jAym2d8VhT_NbCRyw   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0    1.0       0      0     0   \n",
       "1    5.0       0      0     0   \n",
       "2    5.0       0      0     0   \n",
       "3    1.0       0      0     0   \n",
       "4    2.0       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  I bought a Fender 1966 Telecaster that the sal...  2022-01-01 15:47:07   \n",
       "1  This is our go to for take out when I visit my...  2022-01-02 03:49:01   \n",
       "2  Danielle did a great job!  She listened and cu...  2022-01-03 03:17:03   \n",
       "3  We saw a lot of roaches in the bathroom when w...  2022-01-05 15:55:59   \n",
       "4  We  Ordered pork fried rice and beef chow mei ...  2022-01-06 03:59:21   \n",
       "\n",
       "   year                                         categories  business_open  \n",
       "0  2022  Shopping, Musical Instrument Services, Musical...              1  \n",
       "1  2022                         Restaurants, Mediterranean              1  \n",
       "2  2022  Hair Salons, Men's Hair Salons, Barbers, Beaut...              1  \n",
       "3  2022  Hotels & Travel, Hotels, Venues & Event Spaces...              1  \n",
       "4  2022                         Restaurants, Chinese, Thai              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to your Parquet file\n",
    "parquet_file_path = '../filtered/yelp_reviews_2022.parquet'\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "reviews_df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef17ac1-c8f2-4e94-9a57-e49fdb119e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38463dd5-ac26-4e63-94dd-ea7b910fc459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/safarifgisa/venvs/python3/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:1025: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/Users/safarifgisa/venvs/python3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of Gemma3TextModel were not initialized from the model checkpoint at google/gemma-3-1b-it and are newly initialized: ['embed_tokens.weight', 'layers.0.input_layernorm.weight', 'layers.0.mlp.down_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.post_attention_layernorm.weight', 'layers.0.post_feedforward_layernorm.weight', 'layers.0.pre_feedforward_layernorm.weight', 'layers.0.self_attn.k_norm.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.self_attn.q_norm.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.1.input_layernorm.weight', 'layers.1.mlp.down_proj.weight', 'layers.1.mlp.gate_proj.weight', 'layers.1.mlp.up_proj.weight', 'layers.1.post_attention_layernorm.weight', 'layers.1.post_feedforward_layernorm.weight', 'layers.1.pre_feedforward_layernorm.weight', 'layers.1.self_attn.k_norm.weight', 'layers.1.self_attn.k_proj.weight', 'layers.1.self_attn.o_proj.weight', 'layers.1.self_attn.q_norm.weight', 'layers.1.self_attn.q_proj.weight', 'layers.1.self_attn.v_proj.weight', 'layers.10.input_layernorm.weight', 'layers.10.mlp.down_proj.weight', 'layers.10.mlp.gate_proj.weight', 'layers.10.mlp.up_proj.weight', 'layers.10.post_attention_layernorm.weight', 'layers.10.post_feedforward_layernorm.weight', 'layers.10.pre_feedforward_layernorm.weight', 'layers.10.self_attn.k_norm.weight', 'layers.10.self_attn.k_proj.weight', 'layers.10.self_attn.o_proj.weight', 'layers.10.self_attn.q_norm.weight', 'layers.10.self_attn.q_proj.weight', 'layers.10.self_attn.v_proj.weight', 'layers.11.input_layernorm.weight', 'layers.11.mlp.down_proj.weight', 'layers.11.mlp.gate_proj.weight', 'layers.11.mlp.up_proj.weight', 'layers.11.post_attention_layernorm.weight', 'layers.11.post_feedforward_layernorm.weight', 'layers.11.pre_feedforward_layernorm.weight', 'layers.11.self_attn.k_norm.weight', 'layers.11.self_attn.k_proj.weight', 'layers.11.self_attn.o_proj.weight', 'layers.11.self_attn.q_norm.weight', 'layers.11.self_attn.q_proj.weight', 'layers.11.self_attn.v_proj.weight', 'layers.12.input_layernorm.weight', 'layers.12.mlp.down_proj.weight', 'layers.12.mlp.gate_proj.weight', 'layers.12.mlp.up_proj.weight', 'layers.12.post_attention_layernorm.weight', 'layers.12.post_feedforward_layernorm.weight', 'layers.12.pre_feedforward_layernorm.weight', 'layers.12.self_attn.k_norm.weight', 'layers.12.self_attn.k_proj.weight', 'layers.12.self_attn.o_proj.weight', 'layers.12.self_attn.q_norm.weight', 'layers.12.self_attn.q_proj.weight', 'layers.12.self_attn.v_proj.weight', 'layers.13.input_layernorm.weight', 'layers.13.mlp.down_proj.weight', 'layers.13.mlp.gate_proj.weight', 'layers.13.mlp.up_proj.weight', 'layers.13.post_attention_layernorm.weight', 'layers.13.post_feedforward_layernorm.weight', 'layers.13.pre_feedforward_layernorm.weight', 'layers.13.self_attn.k_norm.weight', 'layers.13.self_attn.k_proj.weight', 'layers.13.self_attn.o_proj.weight', 'layers.13.self_attn.q_norm.weight', 'layers.13.self_attn.q_proj.weight', 'layers.13.self_attn.v_proj.weight', 'layers.14.input_layernorm.weight', 'layers.14.mlp.down_proj.weight', 'layers.14.mlp.gate_proj.weight', 'layers.14.mlp.up_proj.weight', 'layers.14.post_attention_layernorm.weight', 'layers.14.post_feedforward_layernorm.weight', 'layers.14.pre_feedforward_layernorm.weight', 'layers.14.self_attn.k_norm.weight', 'layers.14.self_attn.k_proj.weight', 'layers.14.self_attn.o_proj.weight', 'layers.14.self_attn.q_norm.weight', 'layers.14.self_attn.q_proj.weight', 'layers.14.self_attn.v_proj.weight', 'layers.15.input_layernorm.weight', 'layers.15.mlp.down_proj.weight', 'layers.15.mlp.gate_proj.weight', 'layers.15.mlp.up_proj.weight', 'layers.15.post_attention_layernorm.weight', 'layers.15.post_feedforward_layernorm.weight', 'layers.15.pre_feedforward_layernorm.weight', 'layers.15.self_attn.k_norm.weight', 'layers.15.self_attn.k_proj.weight', 'layers.15.self_attn.o_proj.weight', 'layers.15.self_attn.q_norm.weight', 'layers.15.self_attn.q_proj.weight', 'layers.15.self_attn.v_proj.weight', 'layers.16.input_layernorm.weight', 'layers.16.mlp.down_proj.weight', 'layers.16.mlp.gate_proj.weight', 'layers.16.mlp.up_proj.weight', 'layers.16.post_attention_layernorm.weight', 'layers.16.post_feedforward_layernorm.weight', 'layers.16.pre_feedforward_layernorm.weight', 'layers.16.self_attn.k_norm.weight', 'layers.16.self_attn.k_proj.weight', 'layers.16.self_attn.o_proj.weight', 'layers.16.self_attn.q_norm.weight', 'layers.16.self_attn.q_proj.weight', 'layers.16.self_attn.v_proj.weight', 'layers.17.input_layernorm.weight', 'layers.17.mlp.down_proj.weight', 'layers.17.mlp.gate_proj.weight', 'layers.17.mlp.up_proj.weight', 'layers.17.post_attention_layernorm.weight', 'layers.17.post_feedforward_layernorm.weight', 'layers.17.pre_feedforward_layernorm.weight', 'layers.17.self_attn.k_norm.weight', 'layers.17.self_attn.k_proj.weight', 'layers.17.self_attn.o_proj.weight', 'layers.17.self_attn.q_norm.weight', 'layers.17.self_attn.q_proj.weight', 'layers.17.self_attn.v_proj.weight', 'layers.18.input_layernorm.weight', 'layers.18.mlp.down_proj.weight', 'layers.18.mlp.gate_proj.weight', 'layers.18.mlp.up_proj.weight', 'layers.18.post_attention_layernorm.weight', 'layers.18.post_feedforward_layernorm.weight', 'layers.18.pre_feedforward_layernorm.weight', 'layers.18.self_attn.k_norm.weight', 'layers.18.self_attn.k_proj.weight', 'layers.18.self_attn.o_proj.weight', 'layers.18.self_attn.q_norm.weight', 'layers.18.self_attn.q_proj.weight', 'layers.18.self_attn.v_proj.weight', 'layers.19.input_layernorm.weight', 'layers.19.mlp.down_proj.weight', 'layers.19.mlp.gate_proj.weight', 'layers.19.mlp.up_proj.weight', 'layers.19.post_attention_layernorm.weight', 'layers.19.post_feedforward_layernorm.weight', 'layers.19.pre_feedforward_layernorm.weight', 'layers.19.self_attn.k_norm.weight', 'layers.19.self_attn.k_proj.weight', 'layers.19.self_attn.o_proj.weight', 'layers.19.self_attn.q_norm.weight', 'layers.19.self_attn.q_proj.weight', 'layers.19.self_attn.v_proj.weight', 'layers.2.input_layernorm.weight', 'layers.2.mlp.down_proj.weight', 'layers.2.mlp.gate_proj.weight', 'layers.2.mlp.up_proj.weight', 'layers.2.post_attention_layernorm.weight', 'layers.2.post_feedforward_layernorm.weight', 'layers.2.pre_feedforward_layernorm.weight', 'layers.2.self_attn.k_norm.weight', 'layers.2.self_attn.k_proj.weight', 'layers.2.self_attn.o_proj.weight', 'layers.2.self_attn.q_norm.weight', 'layers.2.self_attn.q_proj.weight', 'layers.2.self_attn.v_proj.weight', 'layers.20.input_layernorm.weight', 'layers.20.mlp.down_proj.weight', 'layers.20.mlp.gate_proj.weight', 'layers.20.mlp.up_proj.weight', 'layers.20.post_attention_layernorm.weight', 'layers.20.post_feedforward_layernorm.weight', 'layers.20.pre_feedforward_layernorm.weight', 'layers.20.self_attn.k_norm.weight', 'layers.20.self_attn.k_proj.weight', 'layers.20.self_attn.o_proj.weight', 'layers.20.self_attn.q_norm.weight', 'layers.20.self_attn.q_proj.weight', 'layers.20.self_attn.v_proj.weight', 'layers.21.input_layernorm.weight', 'layers.21.mlp.down_proj.weight', 'layers.21.mlp.gate_proj.weight', 'layers.21.mlp.up_proj.weight', 'layers.21.post_attention_layernorm.weight', 'layers.21.post_feedforward_layernorm.weight', 'layers.21.pre_feedforward_layernorm.weight', 'layers.21.self_attn.k_norm.weight', 'layers.21.self_attn.k_proj.weight', 'layers.21.self_attn.o_proj.weight', 'layers.21.self_attn.q_norm.weight', 'layers.21.self_attn.q_proj.weight', 'layers.21.self_attn.v_proj.weight', 'layers.22.input_layernorm.weight', 'layers.22.mlp.down_proj.weight', 'layers.22.mlp.gate_proj.weight', 'layers.22.mlp.up_proj.weight', 'layers.22.post_attention_layernorm.weight', 'layers.22.post_feedforward_layernorm.weight', 'layers.22.pre_feedforward_layernorm.weight', 'layers.22.self_attn.k_norm.weight', 'layers.22.self_attn.k_proj.weight', 'layers.22.self_attn.o_proj.weight', 'layers.22.self_attn.q_norm.weight', 'layers.22.self_attn.q_proj.weight', 'layers.22.self_attn.v_proj.weight', 'layers.23.input_layernorm.weight', 'layers.23.mlp.down_proj.weight', 'layers.23.mlp.gate_proj.weight', 'layers.23.mlp.up_proj.weight', 'layers.23.post_attention_layernorm.weight', 'layers.23.post_feedforward_layernorm.weight', 'layers.23.pre_feedforward_layernorm.weight', 'layers.23.self_attn.k_norm.weight', 'layers.23.self_attn.k_proj.weight', 'layers.23.self_attn.o_proj.weight', 'layers.23.self_attn.q_norm.weight', 'layers.23.self_attn.q_proj.weight', 'layers.23.self_attn.v_proj.weight', 'layers.24.input_layernorm.weight', 'layers.24.mlp.down_proj.weight', 'layers.24.mlp.gate_proj.weight', 'layers.24.mlp.up_proj.weight', 'layers.24.post_attention_layernorm.weight', 'layers.24.post_feedforward_layernorm.weight', 'layers.24.pre_feedforward_layernorm.weight', 'layers.24.self_attn.k_norm.weight', 'layers.24.self_attn.k_proj.weight', 'layers.24.self_attn.o_proj.weight', 'layers.24.self_attn.q_norm.weight', 'layers.24.self_attn.q_proj.weight', 'layers.24.self_attn.v_proj.weight', 'layers.25.input_layernorm.weight', 'layers.25.mlp.down_proj.weight', 'layers.25.mlp.gate_proj.weight', 'layers.25.mlp.up_proj.weight', 'layers.25.post_attention_layernorm.weight', 'layers.25.post_feedforward_layernorm.weight', 'layers.25.pre_feedforward_layernorm.weight', 'layers.25.self_attn.k_norm.weight', 'layers.25.self_attn.k_proj.weight', 'layers.25.self_attn.o_proj.weight', 'layers.25.self_attn.q_norm.weight', 'layers.25.self_attn.q_proj.weight', 'layers.25.self_attn.v_proj.weight', 'layers.3.input_layernorm.weight', 'layers.3.mlp.down_proj.weight', 'layers.3.mlp.gate_proj.weight', 'layers.3.mlp.up_proj.weight', 'layers.3.post_attention_layernorm.weight', 'layers.3.post_feedforward_layernorm.weight', 'layers.3.pre_feedforward_layernorm.weight', 'layers.3.self_attn.k_norm.weight', 'layers.3.self_attn.k_proj.weight', 'layers.3.self_attn.o_proj.weight', 'layers.3.self_attn.q_norm.weight', 'layers.3.self_attn.q_proj.weight', 'layers.3.self_attn.v_proj.weight', 'layers.4.input_layernorm.weight', 'layers.4.mlp.down_proj.weight', 'layers.4.mlp.gate_proj.weight', 'layers.4.mlp.up_proj.weight', 'layers.4.post_attention_layernorm.weight', 'layers.4.post_feedforward_layernorm.weight', 'layers.4.pre_feedforward_layernorm.weight', 'layers.4.self_attn.k_norm.weight', 'layers.4.self_attn.k_proj.weight', 'layers.4.self_attn.o_proj.weight', 'layers.4.self_attn.q_norm.weight', 'layers.4.self_attn.q_proj.weight', 'layers.4.self_attn.v_proj.weight', 'layers.5.input_layernorm.weight', 'layers.5.mlp.down_proj.weight', 'layers.5.mlp.gate_proj.weight', 'layers.5.mlp.up_proj.weight', 'layers.5.post_attention_layernorm.weight', 'layers.5.post_feedforward_layernorm.weight', 'layers.5.pre_feedforward_layernorm.weight', 'layers.5.self_attn.k_norm.weight', 'layers.5.self_attn.k_proj.weight', 'layers.5.self_attn.o_proj.weight', 'layers.5.self_attn.q_norm.weight', 'layers.5.self_attn.q_proj.weight', 'layers.5.self_attn.v_proj.weight', 'layers.6.input_layernorm.weight', 'layers.6.mlp.down_proj.weight', 'layers.6.mlp.gate_proj.weight', 'layers.6.mlp.up_proj.weight', 'layers.6.post_attention_layernorm.weight', 'layers.6.post_feedforward_layernorm.weight', 'layers.6.pre_feedforward_layernorm.weight', 'layers.6.self_attn.k_norm.weight', 'layers.6.self_attn.k_proj.weight', 'layers.6.self_attn.o_proj.weight', 'layers.6.self_attn.q_norm.weight', 'layers.6.self_attn.q_proj.weight', 'layers.6.self_attn.v_proj.weight', 'layers.7.input_layernorm.weight', 'layers.7.mlp.down_proj.weight', 'layers.7.mlp.gate_proj.weight', 'layers.7.mlp.up_proj.weight', 'layers.7.post_attention_layernorm.weight', 'layers.7.post_feedforward_layernorm.weight', 'layers.7.pre_feedforward_layernorm.weight', 'layers.7.self_attn.k_norm.weight', 'layers.7.self_attn.k_proj.weight', 'layers.7.self_attn.o_proj.weight', 'layers.7.self_attn.q_norm.weight', 'layers.7.self_attn.q_proj.weight', 'layers.7.self_attn.v_proj.weight', 'layers.8.input_layernorm.weight', 'layers.8.mlp.down_proj.weight', 'layers.8.mlp.gate_proj.weight', 'layers.8.mlp.up_proj.weight', 'layers.8.post_attention_layernorm.weight', 'layers.8.post_feedforward_layernorm.weight', 'layers.8.pre_feedforward_layernorm.weight', 'layers.8.self_attn.k_norm.weight', 'layers.8.self_attn.k_proj.weight', 'layers.8.self_attn.o_proj.weight', 'layers.8.self_attn.q_norm.weight', 'layers.8.self_attn.q_proj.weight', 'layers.8.self_attn.v_proj.weight', 'layers.9.input_layernorm.weight', 'layers.9.mlp.down_proj.weight', 'layers.9.mlp.gate_proj.weight', 'layers.9.mlp.up_proj.weight', 'layers.9.post_attention_layernorm.weight', 'layers.9.post_feedforward_layernorm.weight', 'layers.9.pre_feedforward_layernorm.weight', 'layers.9.self_attn.k_norm.weight', 'layers.9.self_attn.k_proj.weight', 'layers.9.self_attn.o_proj.weight', 'layers.9.self_attn.q_norm.weight', 'layers.9.self_attn.q_proj.weight', 'layers.9.self_attn.v_proj.weight', 'norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (2000, 1152)\n"
     ]
    }
   ],
   "source": [
    "llm_model = MyLLMEmbedder(\"google/gemma-3-1b-it\") #Gemma-3-1B-IT\n",
    "embeddings = llm_model.transform_sentences(reviews[:2000])\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fd7ce4-fe0b-457e-afd0-d51ca1890027",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"gemma_embeddings.npy\", embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
